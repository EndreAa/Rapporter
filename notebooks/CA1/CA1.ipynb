{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the fish data through the API with requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizer import Tokenizer\n",
    "from weeksummary import WeekSummary\n",
    "from cassandra.cluster import Cluster\n",
    "import requests\n",
    "# from credentials import config\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, col\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token request successful\n",
      "{'access_token': 'eyJhbGciOiJSUzI1NiIsImtpZCI6IjBCM0I1NEUyRkQ5OUZCQkY5NzVERDMxNDBDREQ4OEI1QzA5RkFDRjNSUzI1NiIsIng1dCI6IkN6dFU0djJaLTctWFhkTVVETjJJdGNDZnJQTSIsInR5cCI6ImF0K2p3dCJ9.eyJpc3MiOiJodHRwczovL2lkLmJhcmVudHN3YXRjaC5ubyIsIm5iZiI6MTcwMTY0ODc3NiwiaWF0IjoxNzAxNjQ4Nzc2LCJleHAiOjE3MDE2NTIzNzYsImF1ZCI6ImFwaSIsInNjb3BlIjpbImFwaSJdLCJjbGllbnRfaWQiOiJlbmRyZWFzZ0BnbWFpbC5jb206SU5EX0NBIn0.CkVsMf4maUzNkSfnxgy2sFMsBezVWQVA7cU7Xm5CqjV_e1K2PzogZYKKZSL7mkNHhNsiwWORRzZ7Z1ASw4Xi3Zg9LfeAw-nsfPsodd8TuAT3v4oZr4Gew2rl1X2NhVtzRc3JIx5nF2kq52ZFB7xYuvWWzPQr_D1Ku8PlIbtZvdfxanJ-EBkVUtZkYmDsEOkW4Q_L9zVKac30ChsqoB6QU6qcI8p0hR7Y4HLc6B-4nOFdHFvZGYbgAcmGjkj4M90OYBiFWY_Ykmu1aLNfla0qf_IcpnakkJwwe9KeMiwanUuvjf13kn6lnEdY8se3BWaJCUqqlSiXWjn_WnaGVD54PHc5rfkucn9VN7FpS4D4LSfnVTCPuIWK8ec_5muuwOlyGcpe0K9abAoj-Mvmlp2Jk-d2ixMePc8VL7vPQoDUD7ojvth7RCkSroTkQc7-cfusPEHwTNHBfvh5szsVu4WhNrDpWi3Ds08FQQ6iQIcaIAUyzthrCoEbI3-QIzJsICK2AucsoLSESmW01wC6gSZAsC6yokgRO5ozsQlNM0SAHY_EvaQvt5nW4S_iKf3TF02TiDU4_U8qC3PiIgqCy9k6YUx0fx52Vtufr5-YFPR_WDvCf0_0ppCSPA1y7jMs9730i5LoD5IJCC0Z-aVfLBOQKkDqCtq13eiM9W302HBeI-M', 'expires_in': 3600, 'token_type': 'Bearer', 'scope': 'api'}\n"
     ]
    }
   ],
   "source": [
    "TOKEN = Tokenizer().get_token() # getting token\n",
    "print(TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see we have three main columns; loalities, week and year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x122be4c40>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cluster = Cluster(['localhost'], port=9042) # connecting to cassandra\n",
    "session = cluster.connect() # creating session\n",
    "session.execute(\"CREATE KEYSPACE IF NOT EXISTS fishhealth WITH REPLICATION = { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\") # creating keyspace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.set_keyspace('fishhealth') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_stmt = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS locality_summary (\n",
    "    localityNo int,\n",
    "    localityWeekId int,\n",
    "    name text,\n",
    "    hasReportedLice boolean,\n",
    "    isFallow boolean,\n",
    "    avgAdultFemaleLice float,\n",
    "    hasCleanerfishDeployed boolean,\n",
    "    hasMechanicalRemoval boolean,\n",
    "    hasSubstanceTreatments boolean,\n",
    "    hasPd boolean,\n",
    "    hasIla boolean,\n",
    "    municipalityNo text,\n",
    "    municipality text,\n",
    "    lat float,\n",
    "    lon float,\n",
    "    isOnLand boolean,\n",
    "    inFilteredSelection boolean,\n",
    "    hasSalmonoids boolean,\n",
    "    isSlaughterHoldingCage boolean,\n",
    "    week int,\n",
    "    year int,\n",
    "    PRIMARY KEY ((localityNo), week)\n",
    ");\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x104f4e980>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute(create_table_stmt) # creating table with columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYSPARK_PYTHON\"] = \"python\" \n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"python\"\n",
    "os.environ[\"PYSPARK_HADOOP_VERSION\"] = \"without\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/04 01:12:57 WARN Utils: Your hostname, Endres-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.11.87 instead (on interface en0)\n",
      "23/12/04 01:12:57 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Ivy Default Cache set to: /Users/endreasgard/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/endreasgard/.ivy2/jars\n",
      "com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-1d426848-ee88-4b78-b9da-969c04dd82b0;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/endreasgard/miniconda3/envs/IND320/lib/python3.10/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound com.datastax.spark#spark-cassandra-connector_2.12;3.4.1 in central\n",
      "\tfound com.datastax.spark#spark-cassandra-connector-driver_2.12;3.4.1 in central\n",
      "\tfound org.scala-lang.modules#scala-collection-compat_2.12;2.11.0 in central\n",
      "\tfound com.datastax.oss#java-driver-core-shaded;4.13.0 in central\n",
      "\tfound com.datastax.oss#native-protocol;1.5.0 in central\n",
      "\tfound com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in central\n",
      "\tfound com.typesafe#config;1.4.1 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.26 in central\n",
      "\tfound io.dropwizard.metrics#metrics-core;4.1.18 in central\n",
      "\tfound org.hdrhistogram#HdrHistogram;2.1.12 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.3 in central\n",
      "\tfound com.github.stephenc.jcip#jcip-annotations;1.0-1 in central\n",
      "\tfound com.github.spotbugs#spotbugs-annotations;3.1.12 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound com.datastax.oss#java-driver-mapper-runtime;4.13.0 in central\n",
      "\tfound com.datastax.oss#java-driver-query-builder;4.13.0 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.10 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.8 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.11 in central\n",
      ":: resolution report :: resolve 292ms :: artifacts dl 8ms\n",
      "\t:: modules in use:\n",
      "\tcom.datastax.oss#java-driver-core-shaded;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-mapper-runtime;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-query-builder;4.13.0 from central in [default]\n",
      "\tcom.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from central in [default]\n",
      "\tcom.datastax.oss#native-protocol;1.5.0 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector-driver_2.12;3.4.1 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector_2.12;3.4.1 from central in [default]\n",
      "\tcom.github.spotbugs#spotbugs-annotations;3.1.12 from central in [default]\n",
      "\tcom.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.8 from central in [default]\n",
      "\tcom.typesafe#config;1.4.1 from central in [default]\n",
      "\tio.dropwizard.metrics#metrics-core;4.1.18 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.10 from central in [default]\n",
      "\torg.hdrhistogram#HdrHistogram;2.1.12 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.3 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.11 from central in [default]\n",
      "\torg.scala-lang.modules#scala-collection-compat_2.12;2.11.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.26 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   19  |   0   |   0   |   0   ||   19  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-1d426848-ee88-4b78-b9da-969c04dd82b0\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 19 already retrieved (0kB/6ms)\n",
      "23/12/04 01:12:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkCassandraApp').\\\n",
    "    config('spark.jars.packages', 'com.datastax.spark:spark-cassandra-connector_2.12:3.4.1').\\\n",
    "    config('spark.cassandra.connection.host', 'localhost').\\\n",
    "    config('spark.sql.extensions', 'com.datastax.spark.connector.CassandraSparkExtensions').\\\n",
    "    config('spark.sql.catalog.mycatalog', 'com.datastax.spark.connector.datasource.CassandraCatalog').\\\n",
    "    config('spark.cassandra.connection.port', '9042').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the data through a simple loop, \n",
    "storage = pd.DataFrame()\n",
    "year = 2022\n",
    "for week in range(1, 53):\n",
    "    week_summary = WeekSummary(TOKEN).get_summary(year, week)\n",
    "    datum = pd.DataFrame(week_summary['localities'])\n",
    "    datum['week'] = week\n",
    "    datum['year'] = year\n",
    "    \n",
    "    # Concatenate the current week's data with the storage DataFrame\n",
    "    storage = pd.concat([storage, datum], ignore_index=True)\n",
    "\n",
    "# Now, storage contains all the records\n",
    "records = storage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records['week'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/04 01:13:09 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+------------+---------------+--------+------------------+----------------------+--------------------+----------------------+-----+------+--------------+--------------------+---------+---------+--------+-------------------+-------------+----------------------+----+----+\n",
      "|localityNo|localityWeekId|        name|hasReportedLice|isFallow|avgAdultFemaleLice|hasCleanerfishDeployed|hasMechanicalRemoval|hasSubstanceTreatments|hasPd|hasIla|municipalityNo|        municipality|      lat|      lon|isOnLand|inFilteredSelection|hasSalmonoids|isSlaughterHoldingCage|week|year|\n",
      "+----------+--------------+------------+---------------+--------+------------------+----------------------+--------------------+----------------------+-----+------+--------------+--------------------+---------+---------+--------+-------------------+-------------+----------------------+----+----+\n",
      "|     14746|       1344789|     Aarsand|          false|    true|               NaN|                 false|               false|                 false|false| false|          1811|              Bindal|65.045867|12.156933|   false|               true|        false|                 false|   1|2022|\n",
      "|     31937|       1345158|    Abelsnes|          false|    true|               NaN|                 false|               false|                 false|false| false|          4207|         Flekkefjord|58.238767|  6.65665|    true|               true|        false|                 false|   1|2022|\n",
      "|     10665|       1344175|    Adamselv|          false|    true|               NaN|                 false|               false|                 false|false| false|          5438|             Lebesby|   70.408|26.691333|    true|               true|         true|                 false|   1|2022|\n",
      "|     29196|       1345110|  Adjetjohka|          false|    true|               NaN|                 false|               false|                 false|false| false|          5430|Guovdageaidnu - K...|68.944137|22.918715|    true|               true|        false|                 false|   1|2022|\n",
      "|     13823|       1344733| Ådlandsvatn|          false|    true|               NaN|                 false|               false|                 false|false| false|          4614|               Stord| 59.79135| 5.500367|    true|               true|         true|                 false|   1|2022|\n",
      "|     33437|       1345181|  Ådnaholmen|          false|    true|               NaN|                 false|               false|                 false|false| false|          1103|           Stavanger|59.278067| 5.777617|   false|               true|         true|                 false|   1|2022|\n",
      "|     30196|       1343765|  Ådnekvamme|          false|    true|               NaN|                 false|               false|                 false|false| false|          4634|          Masfjorden| 60.83205| 5.355017|   false|               true|         true|                 false|   1|2022|\n",
      "|     35297|       1343936|    Ådnøy Sø|           true|   false|              0.05|                 false|               false|                 false|false| false|          1108|             Sandnes| 58.91455| 6.028583|   false|               true|         true|                 false|   1|2022|\n",
      "|     12084|       1344390|        Ænes|          false|    true|               NaN|                 false|               false|                 false|false| false|          4617|          Kvinnherad|60.089167|     6.11|    true|               true|         true|                 false|   1|2022|\n",
      "|     30977|       1343790|       Æsøya|           true|   false|               0.0|                 false|               false|                 false|false| false|          1860|           Vestvågøy|68.104867|13.790067|   false|               true|         true|                 false|   1|2022|\n",
      "|     33717|       1345184|    Æsvika I|          false|    true|               NaN|                 false|               false|                 false|false| false|          1837|               Meløy|66.741267|  13.5144|    true|               true|        false|                 false|   1|2022|\n",
      "|     15196|       1343524|       Aga Ø|           true|   false|              0.03|                 false|               false|                 false|false| false|          4613|               Bømlo|59.845917|  5.26075|   false|               true|         true|                 false|   1|2022|\n",
      "|     11507|       1344285|   Agapollen|          false|    true|               NaN|                 false|               false|                 false|false| false|          4613|               Bømlo| 59.83985| 5.247117|   false|               true|        false|                 false|   1|2022|\n",
      "|     45040|       1345400|  Agnalsvika|          false|    true|               NaN|                 false|               false|                 false|false| false|          4645|             Askvoll|61.321667| 5.206117|   false|               true|        false|                 false|   1|2022|\n",
      "|     10331|       1342980|        Åkre|          false|    true|               NaN|                 false|               false|                 false|false| false|          4617|          Kvinnherad|60.112833| 6.044717|   false|               true|         true|                 false|   1|2022|\n",
      "|     32938|       1345170|Åkrestrømmen|          false|    true|               NaN|                 false|               false|                 false|false| false|          3424|            Rendalen|61.698083| 11.22655|    true|               true|        false|                 false|   1|2022|\n",
      "|     12067|       1343245|     Aldalen|           true|   false|              0.02|                 false|               false|                 false|false| false|          4624|       Bjørnafjorden| 60.24995| 5.571917|   false|               true|         true|                 false|   1|2022|\n",
      "|     12982|       1343359|    Aldeøyna|          false|    true|               NaN|                 false|               false|                 false|false| false|          4645|             Askvoll| 61.31055| 4.767783|   false|               true|         true|                 false|   1|2022|\n",
      "|     10298|       1342970|      Ålforo|           true|   false|              0.13|                 false|               false|                 false|false| false|          4615|              Fitjar|59.866417|   5.2447|   false|               true|         true|                 false|   1|2022|\n",
      "|     45106|       1345452|       Alida|          false|    true|               NaN|                 false|               false|                 false|false| false|          1577|               Volda|62.186167| 5.982317|   false|               true|        false|                 false|   1|2022|\n",
      "+----------+--------------+------------+---------------+--------+------------------+----------------------+--------------------+----------------------+-----+------+--------------+--------------------+---------+---------+--------+-------------------+-------------+----------------------+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(records)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[localityNo: bigint, localityWeekId: bigint, name: string, hasReportedLice: boolean, isFallow: boolean, avgAdultFemaleLice: double, hasCleanerfishDeployed: boolean, hasMechanicalRemoval: boolean, hasSubstanceTreatments: boolean, hasPd: boolean, hasIla: boolean, municipalityNo: string, municipality: string, lat: double, lon: double, isOnLand: boolean, inFilteredSelection: boolean, hasSalmonoids: boolean, isSlaughterHoldingCage: boolean, week: bigint, year: bigint]>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------+---------------+--------+------------------+----------------------+--------------------+----------------------+-----+------+--------------+------------+---------+---------+--------+-------------------+-------------+----------------------+----+----+\n",
      "|localityno|localityweekid|    name|hasreportedlice|isfallow|avgadultfemalelice|hascleanerfishdeployed|hasmechanicalremoval|hassubstancetreatments|haspd|hasila|municipalityno|municipality|      lat|      lon|isonland|infilteredselection|hassalmonoids|isslaughterholdingcage|week|year|\n",
      "+----------+--------------+--------+---------------+--------+------------------+----------------------+--------------------+----------------------+-----+------+--------------+------------+---------+---------+--------+-------------------+-------------+----------------------+----+----+\n",
      "|     14746|       1344789| Aarsand|          false|    true|               NaN|                 false|               false|                 false|false| false|          1811|      Bindal|65.045867|12.156933|   false|               true|        false|                 false|   1|2022|\n",
      "|     31937|       1345158|Abelsnes|          false|    true|               NaN|                 false|               false|                 false|false| false|          4207| Flekkefjord|58.238767|  6.65665|    true|               true|        false|                 false|   1|2022|\n",
      "|     10665|       1344175|Adamselv|          false|    true|               NaN|                 false|               false|                 false|false| false|          5438|     Lebesby|   70.408|26.691333|    true|               true|         true|                 false|   1|2022|\n",
      "+----------+--------------+--------+---------------+--------+------------------+----------------------+--------------------+----------------------+-----+------+--------------+------------+---------+---------+--------+-------------------+-------------+----------------------+----+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selected_df = df.selectExpr(\"localityNo as localityno\", \"localityWeekId as localityweekid\", \"name\", \"hasReportedLice as hasreportedlice\", \"isFallow as isfallow\", \"avgAdultFemaleLice as avgadultfemalelice\", \"hasCleanerfishDeployed as hascleanerfishdeployed\", \"hasMechanicalRemoval as hasmechanicalremoval\", \"hasSubstanceTreatments as hassubstancetreatments\", \"hasPd as haspd\", \"hasIla as hasila\", \"municipalityNo as municipalityno\", \"municipality\", \"lat\", \"lon\", \"isOnLand as isonland\", \"inFilteredSelection as infilteredselection\", \"hasSalmonoids as hassalmonoids\", \"isSlaughterHoldingCage as isslaughterholdingcage\", \"week\", \"year\") \n",
    "# renaming the columns to match the cassandra table\n",
    "selected_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column: avgadultfemalelice, Type: float\n",
      "Column: hascleanerfishdeployed, Type: boolean\n",
      "Column: hasila, Type: boolean\n",
      "Column: hasmechanicalremoval, Type: boolean\n",
      "Column: haspd, Type: boolean\n",
      "Column: hasreportedlice, Type: boolean\n",
      "Column: hassalmonoids, Type: boolean\n",
      "Column: hassubstancetreatments, Type: boolean\n",
      "Column: infilteredselection, Type: boolean\n",
      "Column: isfallow, Type: boolean\n",
      "Column: isonland, Type: boolean\n",
      "Column: isslaughterholdingcage, Type: boolean\n",
      "Column: lat, Type: float\n",
      "Column: localityno, Type: int\n",
      "Column: localityweekid, Type: int\n",
      "Column: lon, Type: float\n",
      "Column: municipality, Type: text\n",
      "Column: municipalityno, Type: text\n",
      "Column: name, Type: text\n",
      "Column: week, Type: int\n",
      "Column: year, Type: int\n"
     ]
    }
   ],
   "source": [
    "table_name = 'locality_summary'\n",
    "query = f\"SELECT column_name, type FROM system_schema.columns WHERE table_name = '{table_name}' ALLOW FILTERING;\"\n",
    "\n",
    "result = session.execute(query, )\n",
    "\n",
    "for row in result:\n",
    "    print(f\"Column: {row.column_name}, Type: {row.type}\")\n",
    "\n",
    "# checking if everything is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "selected_df.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .options(table=\"locality_summary\", keyspace=\"fishhealth\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()\n",
    "# saving the data to cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .options(table=\"locality_summary\", keyspace=\"fishhealth\") \\\n",
    "    .load()\n",
    "# reading the data from cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------------------+----------------------+------+--------------------+-----+---------------+-------------+----------------------+-------------------+--------+--------+----------------------+---------+--------------+--------+------------+--------------+----------+----+\n",
      "|localityno|week|avgadultfemalelice|hascleanerfishdeployed|hasila|hasmechanicalremoval|haspd|hasreportedlice|hassalmonoids|hassubstancetreatments|infilteredselection|isfallow|isonland|isslaughterholdingcage|      lat|localityweekid|     lon|municipality|municipalityno|      name|year|\n",
      "+----------+----+------------------+----------------------+------+--------------------+-----+---------------+-------------+----------------------+-------------------+--------+--------+----------------------+---------+--------------+--------+------------+--------------+----------+----+\n",
      "|     30777|   1|               NaN|                 false| false|               false|false|          false|        false|                 false|               true|    true|    true|                 false|61.124016|       1345137|5.996517|    Høyanger|          4638|Slantevika|2022|\n",
      "|     30777|   2|               NaN|                 false| false|               false|false|          false|        false|                 false|               true|    true|    true|                 false|61.124016|       1348706|5.996517|    Høyanger|          4638|Slantevika|2022|\n",
      "|     30777|   3|               NaN|                 false| false|               false|false|          false|        false|                 false|               true|    true|    true|                 false|61.124016|       1351231|5.996517|    Høyanger|          4638|Slantevika|2022|\n",
      "|     30777|   4|               NaN|                 false| false|               false|false|          false|        false|                 false|               true|    true|    true|                 false|61.124016|       1354281|5.996517|    Høyanger|          4638|Slantevika|2022|\n",
      "|     30777|   5|               NaN|                 false| false|               false|false|          false|        false|                 false|               true|    true|    true|                 false|61.124016|       1356807|5.996517|    Høyanger|          4638|Slantevika|2022|\n",
      "+----------+----+------------------+----------------------+------+--------------------+-----+---------------+-------------+----------------------+-------------------+--------+--------+----------------------+---------+--------------+--------+------------+--------------+----------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------------------+----------------------+------+--------------------+-----+---------------+-------------+----------------------+-------------------+--------+--------+----------------------+--------+--------------+---------+------------+--------------+-------------+----+\n",
      "|localityno|week|avgadultfemalelice|hascleanerfishdeployed|hasila|hasmechanicalremoval|haspd|hasreportedlice|hassalmonoids|hassubstancetreatments|infilteredselection|isfallow|isonland|isslaughterholdingcage|     lat|localityweekid|      lon|municipality|municipalityno|         name|year|\n",
      "+----------+----+------------------+----------------------+------+--------------------+-----+---------------+-------------+----------------------+-------------------+--------+--------+----------------------+--------+--------------+---------+------------+--------------+-------------+----+\n",
      "|     13494|   1|               NaN|                 false| false|               false|false|          false|         true|                 false|               true|    true|   false|                  true|64.91637|       1344659|11.251133|   Nærøysund|          5060|Flerengstrand|2022|\n",
      "|     13494|   2|               NaN|                 false| false|               false|false|          false|         true|                 false|               true|    true|   false|                  true|64.91637|       1348228|11.251133|   Nærøysund|          5060|Flerengstrand|2022|\n",
      "|     13494|   3|               NaN|                 false| false|               false|false|          false|         true|                 false|               true|    true|   false|                  true|64.91637|       1350753|11.251133|   Nærøysund|          5060|Flerengstrand|2022|\n",
      "|     13494|   4|               NaN|                 false| false|               false|false|          false|         true|                 false|               true|    true|   false|                  true|64.91637|       1353803|11.251133|   Nærøysund|          5060|Flerengstrand|2022|\n",
      "|     13494|   5|               NaN|                 false| false|               false|false|          false|         true|                 false|               true|    true|   false|                  true|64.91637|       1356329|11.251133|   Nærøysund|          5060|Flerengstrand|2022|\n",
      "|     13494|   6|               NaN|                 false| false|               false|false|          false|         true|                 false|               true|    true|   false|                  true|64.91637|       1358855|11.251133|   Nærøysund|          5060|Flerengstrand|2022|\n",
      "|     13494|   7|               NaN|                 false| false|               false|false|          false|         true|                 false|               true|    true|   false|                  true|64.91637|       1362965|11.251133|   Nærøysund|          5060|Flerengstrand|2022|\n",
      "|     13494|   8|               NaN|                 false| false|               false|false|          false|         true|                 false|               true|    true|   false|                  true|64.91637|       1367081|11.251133|   Nærøysund|          5060|Flerengstrand|2022|\n",
      "|     13494|   9|               NaN|                 false| false|               false|false|          false|         true|                 false|               true|    true|   false|                  true|64.91637|       1370671|11.251133|   Nærøysund|          5060|Flerengstrand|2022|\n",
      "|     13494|  10|               NaN|                 false| false|               false|false|          false|         true|                 false|               true|    true|   false|                  true|64.91637|       1373735|11.251133|   Nærøysund|          5060|Flerengstrand|2022|\n",
      "|     13494|  11|               NaN|                 false| false|               false|false|          false|         true|                 false|               true|    true|   false|                  true|64.91637|       1376269|11.251133|   Nærøysund|          5060|Flerengstrand|2022|\n",
      "|     13494|  12|               NaN|                 false| false|               false|false|          false|         true|                 false|               true|    true|   false|                  true|64.91637|       1379336|11.251133|   Nærøysund|          5060|Flerengstrand|2022|\n",
      "|     13494|  13|               NaN|                 false| false|               false|false|          false|         true|                 false|               true|    true|   false|                  true|64.91637|       1385080|11.251133|   Nærøysund|          5060|Flerengstrand|2022|\n",
      "|     13494|  14|               NaN|                 false| false|               false|false|          false|         true|                 false|               true|    true|   false|                  true|64.91637|       1388691|11.251133|   Nærøysund|          5060|Flerengstrand|2022|\n",
      "|     13494|  15|               NaN|                 false| false|               false|false|          false|         true|                 false|               true|    true|   false|                  true|64.91637|       1391234|11.251133|   Nærøysund|          5060|Flerengstrand|2022|\n",
      "|     13494|  16|               NaN|                 false| false|               false|false|          false|         true|                 false|               true|    true|   false|                  true|64.91637|       1394314|11.251133|   Nærøysund|          5060|Flerengstrand|2022|\n",
      "|     13494|  17|               NaN|                 false| false|               false|false|          false|         true|                 false|               true|    true|   false|                  true|64.91637|       1397397|11.251133|   Nærøysund|          5060|Flerengstrand|2022|\n",
      "|     13494|  18|               NaN|                 false| false|               false|false|          false|         true|                 false|               true|    true|   false|                  true|64.91637|       1399945|11.251133|   Nærøysund|          5060|Flerengstrand|2022|\n",
      "|     13494|  19|               NaN|                 false| false|               false|false|          false|         true|                 false|               true|    true|   false|                  true|64.91637|       1403031|11.251133|   Nærøysund|          5060|Flerengstrand|2022|\n",
      "|     13494|  20|               NaN|                 false| false|               false|false|          false|         true|                 false|               true|    true|   false|                  true|64.91637|       1406118|11.251133|   Nærøysund|          5060|Flerengstrand|2022|\n",
      "+----------+----+------------------+----------------------+------+--------------------+-----+---------------+-------------+----------------------+-------------------+--------+--------+----------------------+--------+--------------+---------+------------+--------------+-------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_data = data.filter(data.municipality == 'Nærøysund') # where I worked this summer :)\n",
    "filtered_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 34797, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 25235, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 10256, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 13181, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 26335, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 13959, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 29016, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12671, 12727, 12727, 12727, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 13581, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 12719, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 45046, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 32057, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 10417, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 34018, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 31357, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 36617, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 37577, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 12652, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 10411, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 21495, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 10262, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 12668, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45085, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 45032, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 30076, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 35797, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 12660, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 45127, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 39797, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 30177, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 39717, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 45061, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 13681, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 10410, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 35877, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12714, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12730, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 12590, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13180, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 13685, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 35197, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 10421, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 13494, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 37177, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 10427, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 18755, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 30997, 45139, 45139, 45139, 45139, 45139, 45139, 45139, 45139, 45139, 45139, 45139, 45139, 45139, 45139, 45139, 45139, 45139, 45139, 45139, 45139, 45139, 45139, 45139, 45139, 45139, 45139, 45139, 45139, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 22775, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315, 26315]\n",
      "[Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Kvitneset'), Row(name='Kvitneset'), Row(name='Kvitneset'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya')]\n"
     ]
    }
   ],
   "source": [
    "#get all the source_id from the filtered data\n",
    "loco = filtered_data.select('localityno').collect()\n",
    "names = filtered_data.select('name').collect()\n",
    "\n",
    "#make a list with only the digits seperated by commas\n",
    "loco_list = []\n",
    "for i in loco:\n",
    "    loco_list.append(i.localityno)\n",
    "print(loco_list)\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Kalvhagan II'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Humulen'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Kyrøyene'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Årsetfjorden'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Helligholmen'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Salsbruket'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Marøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Hjortøya'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Storvikbukta'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Ryumsjøen Reipholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Hindholmen'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Flerengstrand'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Djuptaren'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Kålåstranda'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Klungset'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Risværgalten'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Lille Kvitholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Astridholmen'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Val'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Ramstadholmen'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Lonet I Naustbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Storbukta'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Dolma N'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Geitryggen'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Gjerdinga'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Båfjorden'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Harbakholmen'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Stevika'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Kråkøya'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Hattholmen'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Torlandsøya'), Row(name='Kvitneset'), Row(name='Kvitneset'), Row(name='Kvitneset'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Torgerhaugen'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Svaberget'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Flatskjæret II'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Eiterfjorden'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Ytterflesa'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Lyngøy'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Skrubbholmen'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Sandbukta'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Kvaløya'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Nordgjæslingan'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Kipholmen'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Hellerflesa'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Småholman'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Bondøya'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Osavatnet'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Geitholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Oterholmen'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Båfjordstranda'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya'), Row(name='Stasøya')]\n",
      "+----------+----+------------------+----------------------+------+--------------------+-----+---------------+-------------+----------------------+-------------------+--------+--------+----------------------+--------+--------------+---------+------------+--------------+--------+----+\n",
      "|localityno|week|avgadultfemalelice|hascleanerfishdeployed|hasila|hasmechanicalremoval|haspd|hasreportedlice|hassalmonoids|hassubstancetreatments|infilteredselection|isfallow|isonland|isslaughterholdingcage|     lat|localityweekid|      lon|municipality|municipalityno|    name|year|\n",
      "+----------+----+------------------+----------------------+------+--------------------+-----+---------------+-------------+----------------------+-------------------+--------+--------+----------------------+--------+--------------+---------+------------+--------------+--------+----+\n",
      "|     18755|   1|              0.05|                 false| false|               false|false|           true|         true|                 false|               true|   false|   false|                 false|64.74997|       1343568|11.394183|   Nærøysund|          5060|Klungset|2022|\n",
      "|     18755|   2|              0.07|                 false| false|               false|false|           true|         true|                 false|               true|   false|   false|                 false|64.74997|       1347137|11.394183|   Nærøysund|          5060|Klungset|2022|\n",
      "|     18755|   3|              0.04|                 false| false|               false|false|           true|         true|                 false|               true|   false|   false|                 false|64.74997|       1349662|11.394183|   Nærøysund|          5060|Klungset|2022|\n",
      "|     18755|   4|              0.05|                 false| false|               false|false|           true|         true|                 false|               true|   false|   false|                 false|64.74997|       1352712|11.394183|   Nærøysund|          5060|Klungset|2022|\n",
      "|     18755|   5|              0.07|                 false| false|               false|false|           true|         true|                 false|               true|   false|   false|                 false|64.74997|       1355238|11.394183|   Nærøysund|          5060|Klungset|2022|\n",
      "|     18755|   6|              0.06|                 false| false|               false|false|           true|         true|                 false|               true|   false|   false|                 false|64.74997|       1357764|11.394183|   Nærøysund|          5060|Klungset|2022|\n",
      "|     18755|   7|              0.09|                 false| false|               false|false|           true|         true|                 false|               true|   false|   false|                 false|64.74997|       1361874|11.394183|   Nærøysund|          5060|Klungset|2022|\n",
      "|     18755|   8|              0.15|                 false| false|               false|false|           true|         true|                 false|               true|   false|   false|                 false|64.74997|       1365990|11.394183|   Nærøysund|          5060|Klungset|2022|\n",
      "|     18755|   9|              0.12|                 false| false|               false|false|           true|         true|                 false|               true|   false|   false|                 false|64.74997|       1369580|11.394183|   Nærøysund|          5060|Klungset|2022|\n",
      "|     18755|  10|              0.08|                 false| false|               false|false|           true|         true|                 false|               true|   false|   false|                 false|64.74997|       1372644|11.394183|   Nærøysund|          5060|Klungset|2022|\n",
      "|     18755|  11|              0.07|                 false| false|               false|false|           true|         true|                 false|               true|   false|   false|                 false|64.74997|       1375178|11.394183|   Nærøysund|          5060|Klungset|2022|\n",
      "|     18755|  12|              0.07|                 false| false|               false|false|           true|         true|                 false|               true|   false|   false|                 false|64.74997|       1378245|11.394183|   Nærøysund|          5060|Klungset|2022|\n",
      "|     18755|  13|              0.19|                 false| false|               false|false|           true|         true|                 false|               true|   false|   false|                 false|64.74997|       1383989|11.394183|   Nærøysund|          5060|Klungset|2022|\n",
      "|     18755|  14|              0.11|                 false| false|               false|false|           true|         true|                 false|               true|   false|   false|                 false|64.74997|       1387600|11.394183|   Nærøysund|          5060|Klungset|2022|\n",
      "|     18755|  15|              0.12|                 false| false|               false|false|           true|         true|                 false|               true|   false|   false|                 false|64.74997|       1390143|11.394183|   Nærøysund|          5060|Klungset|2022|\n",
      "|     18755|  16|              0.16|                 false| false|               false|false|           true|         true|                 false|               true|   false|   false|                 false|64.74997|       1393223|11.394183|   Nærøysund|          5060|Klungset|2022|\n",
      "|     18755|  17|              0.18|                 false| false|               false|false|           true|         true|                 false|               true|   false|   false|                 false|64.74997|       1396305|11.394183|   Nærøysund|          5060|Klungset|2022|\n",
      "|     18755|  18|              0.21|                 false| false|               false|false|           true|         true|                 false|               true|   false|   false|                 false|64.74997|       1398850|11.394183|   Nærøysund|          5060|Klungset|2022|\n",
      "|     18755|  19|               0.2|                 false| false|               false|false|           true|         true|                 false|               true|   false|   false|                 false|64.74997|       1401935|11.394183|   Nærøysund|          5060|Klungset|2022|\n",
      "|     18755|  20|              0.26|                 false| false|               false|false|           true|         true|                 false|               true|   false|   false|                 false|64.74997|       1405022|11.394183|   Nærøysund|          5060|Klungset|2022|\n",
      "+----------+----+------------------+----------------------+------+--------------------+-----+---------------+-------------+----------------------+-------------------+--------+--------+----------------------+--------+--------------+---------+------------+--------------+--------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(names)\n",
    "\n",
    "#find localityno for Marøya\n",
    "maroya = filtered_data.filter(filtered_data.name == 'Klungset')\n",
    "maroya.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weeks_data = pd.DataFrame()\n",
    "weeks = range(1, 53)\n",
    "\n",
    "\n",
    "for week in weeks:\n",
    "    # Fetch the summary for the current week\n",
    "    data_1 = WeekSummary(TOKEN).get_summary_lice(year, week, 18755)['localityWeek']\n",
    "    \n",
    "    # Convert single values to lists for compatibility with DataFrame\n",
    "    for key, value in data_1.items():\n",
    "        data_1[key] = [value]\n",
    "    \n",
    "    # Convert the data to a DataFrame and drop unwanted columns\n",
    "    week_data = pd.DataFrame(data_1)\n",
    "    week_data = week_data.drop(columns=[\n",
    "        \"bathTreatments\", \"cleanerFish\", \"inFeedTreatments\",\n",
    "        \"mechanicalRemoval\", \"timeSinceLastChitinSynthesisInhibitorTreatment\"\n",
    "    ])\n",
    "    \n",
    "    # Add year and week information to the DataFrame\n",
    "    week_data['year'] = year\n",
    "    week_data['week'] = week\n",
    "    \n",
    "    # Append this week's data to the all_weeks_data DataFrame\n",
    "    all_weeks_data = pd.concat([all_weeks_data, week_data], ignore_index=True)\n",
    "\n",
    "# all_weeks_data now contains the combined data for all weeks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'localityNo', 'year', 'week', 'hasReportedLice',\n",
       "       'hasMechanicalRemoval', 'hasBathTreatment', 'hasInFeedTreatment',\n",
       "       'hasCleanerFishDeployed', 'isFallow', 'avgAdultFemaleLice',\n",
       "       'avgMobileLice', 'avgStationaryLice', 'seaTemperature', 'hasSalmonoids',\n",
       "       'isSlaughterHoldingCage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_weeks_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "localityno = 18755\n",
    "year = 2022\n",
    "\n",
    "records=[]\n",
    "for week in range(1, 53):  \n",
    "\n",
    "    week_summary = WeekSummary(TOKEN).get_summary_lice(year, week, localityno)\n",
    "    week_summary['liceCountPreviousWeek']['localityno'] = localityno\n",
    "    records.append(week_summary['liceCountPreviousWeek'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>hasReportedLice</th>\n",
       "      <th>avgAdultFemaleLice</th>\n",
       "      <th>avgMobileLice</th>\n",
       "      <th>avgStationaryLice</th>\n",
       "      <th>localityno</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021</td>\n",
       "      <td>52</td>\n",
       "      <td>True</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  week  hasReportedLice  avgAdultFemaleLice  avgMobileLice  \\\n",
       "0  2021    52             True                0.03           0.26   \n",
       "1  2022     1             True                0.05           0.29   \n",
       "2  2022     2             True                0.07           0.28   \n",
       "3  2022     3             True                0.04           0.29   \n",
       "4  2022     4             True                0.05           0.27   \n",
       "\n",
       "   avgStationaryLice  localityno  \n",
       "0                0.0       18755  \n",
       "1                0.0       18755  \n",
       "2                0.0       18755  \n",
       "3                0.0       18755  \n",
       "4                0.0       18755  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(records)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df.query('year != 2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5d/q9qr3j3n583_1nn6rclk38th0000gn/T/ipykernel_90896/2903033980.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_1.sort_values(by=['week'], inplace=True)\n",
      "/var/folders/5d/q9qr3j3n583_1nn6rclk38th0000gn/T/ipykernel_90896/2903033980.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_1['seatemperature'] = all_weeks_data['seaTemperature'].copy()\n"
     ]
    }
   ],
   "source": [
    "df_1.sort_values(by=['week'], inplace=True)\n",
    "all_weeks_data.sort_values(by=['week'], inplace=True)\n",
    "\n",
    "df_1['seatemperature'] = all_weeks_data['seaTemperature'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(df_1['week'], df_1['seatemperature'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>hasReportedLice</th>\n",
       "      <th>avgAdultFemaleLice</th>\n",
       "      <th>avgMobileLice</th>\n",
       "      <th>avgStationaryLice</th>\n",
       "      <th>localityno</th>\n",
       "      <th>seatemperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18755</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18755</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18755</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18755</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18755</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  week  hasReportedLice  avgAdultFemaleLice  avgMobileLice  \\\n",
       "1  2022     1             True                0.05           0.29   \n",
       "2  2022     2             True                0.07           0.28   \n",
       "3  2022     3             True                0.04           0.29   \n",
       "4  2022     4             True                0.05           0.27   \n",
       "5  2022     5             True                0.07           0.27   \n",
       "\n",
       "   avgStationaryLice  localityno  seatemperature  \n",
       "1                0.0       18755             6.5  \n",
       "2                0.0       18755             6.0  \n",
       "3                0.0       18755             5.8  \n",
       "4                0.0       18755             4.9  \n",
       "5                0.0       18755             5.6  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---------------+------------------+-------------+-----------------+----------+--------------+\n",
      "|year|week|hasReportedLice|avgAdultFemaleLice|avgMobileLice|avgStationaryLice|localityno|seatemperature|\n",
      "+----+----+---------------+------------------+-------------+-----------------+----------+--------------+\n",
      "|2022|   1|           true|              0.05|         0.29|              0.0|     18755|           6.5|\n",
      "|2022|   2|           true|              0.07|         0.28|              0.0|     18755|           6.0|\n",
      "|2022|   3|           true|              0.04|         0.29|              0.0|     18755|           5.8|\n",
      "|2022|   4|           true|              0.05|         0.27|              0.0|     18755|           4.9|\n",
      "|2022|   5|           true|              0.07|         0.27|              0.0|     18755|           5.6|\n",
      "|2022|   6|           true|              0.06|         0.23|              0.0|     18755|           5.2|\n",
      "|2022|   7|           true|              0.09|         0.42|              0.0|     18755|           4.9|\n",
      "|2022|   8|           true|              0.15|         0.65|              0.0|     18755|           4.9|\n",
      "|2022|   9|           true|              0.12|         0.55|              0.0|     18755|           4.9|\n",
      "|2022|  10|           true|              0.08|         0.59|              0.0|     18755|           5.2|\n",
      "+----+----+---------------+------------------+-------------+-----------------+----------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = spark.createDataFrame(df_1)\n",
    "df2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: long (nullable = true)\n",
      " |-- week: long (nullable = true)\n",
      " |-- hasReportedLice: boolean (nullable = true)\n",
      " |-- avgAdultFemaleLice: double (nullable = true)\n",
      " |-- avgMobileLice: double (nullable = true)\n",
      " |-- avgStationaryLice: double (nullable = true)\n",
      " |-- localityno: long (nullable = true)\n",
      " |-- seatemperature: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_stmt = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS week_summary (\n",
    "    avgAdultFemaleLice double,\n",
    "    avgMobileLice double,\n",
    "    avgStationaryLice double,\n",
    "    hasReportedLice boolean,\n",
    "    localityno bigint,\n",
    "    seatemperature double,\n",
    "    week bigint, \n",
    "    year bigint,\n",
    "    PRIMARY KEY ((week), localityno));\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x13392cb20>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.execute(create_table_stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------+-----------------+---------------+--------------+----------+----+----+\n",
      "|avgadultfemalelice|avgmobilelice|avgstationarylice|hasreportedlice|seatemperature|localityno|week|year|\n",
      "+------------------+-------------+-----------------+---------------+--------------+----------+----+----+\n",
      "|              0.05|         0.29|              0.0|           true|           6.5|     18755|   1|2022|\n",
      "|              0.07|         0.28|              0.0|           true|           6.0|     18755|   2|2022|\n",
      "|              0.04|         0.29|              0.0|           true|           5.8|     18755|   3|2022|\n",
      "+------------------+-------------+-----------------+---------------+--------------+----------+----+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selected_df2 = df2.selectExpr(\n",
    "    \"avgAdultFemaleLice as avgadultfemalelice\",\n",
    "    \"avgMobileLice as avgmobilelice\",\n",
    "    \"avgStationaryLice as avgstationarylice\",\n",
    "    \"hasReportedLice as hasreportedlice\",\n",
    "    'seatemperature',\n",
    "    \"localityno\",\n",
    "    \"week\",\n",
    "    \"year\"\n",
    ")\n",
    "selected_df2.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/04 06:39:05 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 915358 ms exceeds timeout 120000 ms\n",
      "23/12/04 06:39:05 WARN SparkContext: Killing executors is not supported by current scheduler.\n",
      "23/12/04 06:39:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:39:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:39:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:39:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:39:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:39:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:39:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:39:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:39:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:39:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:39:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:39:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:40:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:40:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:40:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:40:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:40:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:40:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:40:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:40:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:56:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:56:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:57:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:57:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:57:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:57:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:57:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:57:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:57:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:57:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:57:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:57:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:57:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:57:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:58:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:58:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:58:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:58:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:58:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:58:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:58:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:58:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:58:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:58:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:58:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/12/04 06:58:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/12/04 06:59:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/12/04 06:59:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/12/04 06:59:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:59:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:59:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:59:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:59:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:59:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:59:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:59:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:59:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 06:59:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:00:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:00:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:00:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:00:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:00:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:00:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:00:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/12/04 07:00:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/12/04 07:00:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:00:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:00:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:00:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:01:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:01:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:01:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:01:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:01:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:01:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:01:35 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:01:35 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:01:45 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:01:45 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:01:55 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:01:55 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:02:05 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/12/04 07:02:05 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/12/04 07:02:15 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:02:15 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:02:25 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:02:25 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:18:28 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:18:28 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:18:37 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:18:37 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:18:47 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:18:47 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:18:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:18:57 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:19:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:19:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:19:17 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/12/04 07:19:17 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/12/04 07:19:27 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/12/04 07:19:27 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/12/04 07:19:37 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:19:37 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:19:47 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:19:47 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:19:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:19:57 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:20:07 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:20:07 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:20:17 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:20:17 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:20:27 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:20:27 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:20:37 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/12/04 07:20:37 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.dispatchOrAddCallback(Promise.scala:316)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.onComplete(Promise.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.transformWith(Promise.scala:40)\n",
      "\tat scala.concurrent.impl.Promise.transformWith$(Promise.scala:38)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.transformWith(Promise.scala:187)\n",
      "\tat scala.concurrent.Future.flatMap(Future.scala:306)\n",
      "\tat scala.concurrent.Future.flatMap$(Future.scala:306)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.flatMap(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.asyncSetupEndpointRefByURI(NettyRpcEnv.scala:150)\n",
      "\t... 17 more\n",
      "23/12/04 07:20:47 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:20:47 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:20:57 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:20:57 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:358)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:1583)\n",
      "Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:102)\n",
      "\tat org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:110)\n",
      "\tat org.apache.spark.util.RpcUtils$.makeDriverRef(RpcUtils.scala:36)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.driverEndpoint$lzycompute(BlockManagerMasterEndpoint.scala:124)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$driverEndpoint(BlockManagerMasterEndpoint.scala:123)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$lzycompute$1(BlockManagerMasterEndpoint.scala:688)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.isExecutorAlive$1(BlockManagerMasterEndpoint.scala:687)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:725)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "Caused by: org.apache.spark.rpc.RpcEndpointNotFoundException: Cannot find endpoint: spark://CoarseGrainedScheduler@192.168.11.87:63875\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1(NettyRpcEnv.scala:148)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$asyncSetupEndpointRefByURI$1$adapted(NettyRpcEnv.scala:144)\n",
      "\tat scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)\n",
      "\tat scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)\n",
      "\tat scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)\n",
      "\tat scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)\n",
      "\tat scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.trySuccess(Promise.scala:94)\n",
      "\tat scala.concurrent.Promise.trySuccess$(Promise.scala:94)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.trySuccess(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.onSuccess$1(NettyRpcEnv.scala:225)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5(NettyRpcEnv.scala:239)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$5$adapted(NettyRpcEnv.scala:238)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)\n",
      "\tat org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)\n",
      "\tat scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)\n",
      "\tat scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)\n",
      "\tat scala.concurrent.Promise.complete(Promise.scala:53)\n",
      "\tat scala.concurrent.Promise.complete$(Promise.scala:52)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)\n",
      "\tat scala.concurrent.Promise.success(Promise.scala:86)\n",
      "\tat scala.concurrent.Promise.success$(Promise.scala:86)\n",
      "\tat scala.concurrent.impl.Promise$DefaultPromise.success(Promise.scala:187)\n",
      "\tat org.apache.spark.rpc.netty.LocalNettyRpcCallContext.send(NettyRpcCallContext.scala:50)\n",
      "\tat org.apache.spark.rpc.netty.NettyRpcCallContext.reply(NettyRpcCallContext.scala:32)\n",
      "\tat org.apache.spark.rpc.netty.RpcEndpointVerifier$$anonfun$receiveAndReply$1.applyOrElse(RpcEndpointVerifier.scala:31)\n",
      "\t... 8 more\n",
      "23/12/04 07:20:57 ERROR Executor: Exit as unable to send heartbeats to driver more than 60 times\n",
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 63934)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/endreasgard/miniconda3/envs/IND320/lib/python3.10/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/Users/endreasgard/miniconda3/envs/IND320/lib/python3.10/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/Users/endreasgard/miniconda3/envs/IND320/lib/python3.10/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/Users/endreasgard/miniconda3/envs/IND320/lib/python3.10/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/Users/endreasgard/miniconda3/envs/IND320/lib/python3.10/site-packages/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/Users/endreasgard/miniconda3/envs/IND320/lib/python3.10/site-packages/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "  File \"/Users/endreasgard/miniconda3/envs/IND320/lib/python3.10/site-packages/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/Users/endreasgard/miniconda3/envs/IND320/lib/python3.10/site-packages/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "selected_df2.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .options(table=\"week_summary\", keyspace=\"fishhealth\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lice = spark.read \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .options(table=\"week_summary\", keyspace=\"fishhealth\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data and data_lice to pandas dataframes\n",
    "data_pandas = data.toPandas()\n",
    "data_lice_pandas = data_lice.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>localityno</th>\n",
       "      <th>week</th>\n",
       "      <th>avgadultfemalelice</th>\n",
       "      <th>hascleanerfishdeployed</th>\n",
       "      <th>hasila</th>\n",
       "      <th>hasmechanicalremoval</th>\n",
       "      <th>haspd</th>\n",
       "      <th>hasreportedlice</th>\n",
       "      <th>hassalmonoids</th>\n",
       "      <th>hassubstancetreatments</th>\n",
       "      <th>...</th>\n",
       "      <th>isfallow</th>\n",
       "      <th>isonland</th>\n",
       "      <th>isslaughterholdingcage</th>\n",
       "      <th>lat</th>\n",
       "      <th>localityweekid</th>\n",
       "      <th>lon</th>\n",
       "      <th>municipality</th>\n",
       "      <th>municipalityno</th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11365</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>69.050499</td>\n",
       "      <td>1343124</td>\n",
       "      <td>16.883734</td>\n",
       "      <td>Senja</td>\n",
       "      <td>5421</td>\n",
       "      <td>Gjervika</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11365</td>\n",
       "      <td>2</td>\n",
       "      <td>0.03</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>69.050499</td>\n",
       "      <td>1346693</td>\n",
       "      <td>16.883734</td>\n",
       "      <td>Senja</td>\n",
       "      <td>5421</td>\n",
       "      <td>Gjervika</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11365</td>\n",
       "      <td>3</td>\n",
       "      <td>0.03</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>69.050499</td>\n",
       "      <td>1349218</td>\n",
       "      <td>16.883734</td>\n",
       "      <td>Senja</td>\n",
       "      <td>5421</td>\n",
       "      <td>Gjervika</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11365</td>\n",
       "      <td>4</td>\n",
       "      <td>0.03</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>69.050499</td>\n",
       "      <td>1352268</td>\n",
       "      <td>16.883734</td>\n",
       "      <td>Senja</td>\n",
       "      <td>5421</td>\n",
       "      <td>Gjervika</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11365</td>\n",
       "      <td>5</td>\n",
       "      <td>0.02</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>69.050499</td>\n",
       "      <td>1354794</td>\n",
       "      <td>16.883734</td>\n",
       "      <td>Senja</td>\n",
       "      <td>5421</td>\n",
       "      <td>Gjervika</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   localityno  week  avgadultfemalelice  hascleanerfishdeployed  hasila  \\\n",
       "0       11365     1                0.02                   False   False   \n",
       "1       11365     2                0.03                   False   False   \n",
       "2       11365     3                0.03                   False   False   \n",
       "3       11365     4                0.03                   False   False   \n",
       "4       11365     5                0.02                   False   False   \n",
       "\n",
       "   hasmechanicalremoval  haspd  hasreportedlice  hassalmonoids  \\\n",
       "0                 False  False             True           True   \n",
       "1                 False  False             True           True   \n",
       "2                 False  False             True           True   \n",
       "3                 False  False             True           True   \n",
       "4                 False  False             True           True   \n",
       "\n",
       "   hassubstancetreatments  ...  isfallow  isonland  isslaughterholdingcage  \\\n",
       "0                   False  ...     False     False                   False   \n",
       "1                   False  ...     False     False                   False   \n",
       "2                   False  ...     False     False                   False   \n",
       "3                   False  ...     False     False                   False   \n",
       "4                   False  ...     False     False                   False   \n",
       "\n",
       "         lat  localityweekid        lon  municipality municipalityno  \\\n",
       "0  69.050499         1343124  16.883734         Senja           5421   \n",
       "1  69.050499         1346693  16.883734         Senja           5421   \n",
       "2  69.050499         1349218  16.883734         Senja           5421   \n",
       "3  69.050499         1352268  16.883734         Senja           5421   \n",
       "4  69.050499         1354794  16.883734         Senja           5421   \n",
       "\n",
       "       name  year  \n",
       "0  Gjervika  2022  \n",
       "1  Gjervika  2022  \n",
       "2  Gjervika  2022  \n",
       "3  Gjervika  2022  \n",
       "4  Gjervika  2022  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pandas.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week</th>\n",
       "      <th>localityno</th>\n",
       "      <th>avgadultfemalelice</th>\n",
       "      <th>avgmobilelice</th>\n",
       "      <th>avgstationarylice</th>\n",
       "      <th>hasreportedlice</th>\n",
       "      <th>seatemperature</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>18755</td>\n",
       "      <td>0.18</td>\n",
       "      <td>3.31</td>\n",
       "      <td>2.39</td>\n",
       "      <td>True</td>\n",
       "      <td>10.3</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>18755</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>18755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>18755</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>18755</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>True</td>\n",
       "      <td>8.9</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   week  localityno  avgadultfemalelice  avgmobilelice  avgstationarylice  \\\n",
       "0    40       18755                0.18           3.31               2.39   \n",
       "1     8       18755                0.15           0.65               0.00   \n",
       "2    48       18755                 NaN            NaN                NaN   \n",
       "3     5       18755                0.07           0.27               0.00   \n",
       "4    22       18755                0.21           0.19               0.00   \n",
       "\n",
       "   hasreportedlice  seatemperature  year  \n",
       "0             True            10.3  2022  \n",
       "1             True             4.9  2022  \n",
       "2            False             NaN  2022  \n",
       "3             True             5.6  2022  \n",
       "4             True             8.9  2022  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lice_pandas.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "pd_reported = data_pandas['haspd'].value_counts()\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.pie(pd_reported, labels=['No PD Reported', 'PD Reported'], autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Proportions of Reporting Pancreas Disease (PD)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "data = data_pandas[data_pandas['localityno'].isin(data_lice_pandas['localityno'].unique())]\n",
    "# Grouping lice data by week and calculating mean for lice counts\n",
    "lice_weekly_mean = data_lice_pandas.groupby('week')[['avgadultfemalelice', 'avgmobilelice', 'avgstationarylice']].mean()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(lice_weekly_mean['avgadultfemalelice'], label='Adult Female Lice', marker='o')\n",
    "plt.plot(lice_weekly_mean['avgmobilelice'], label='Mobile Lice', marker='o')\n",
    "plt.plot(lice_weekly_mean['avgstationarylice'], label='Stationary Lice', marker='o')\n",
    "plt.title('Average Lice Count as a Function of Time during 2022')\n",
    "plt.xlabel('Week')\n",
    "plt.ylabel('Average Lice Count')\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
